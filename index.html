<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A visuotactile system capable of folding and hanging in-air using dense visual representations and tactilely-supervised visual affordance networks.">
  <meta name="keywords" content="Deformable Object Manipulation, Dense Correspondence Learning, Confidence-Aware Planning, Visuotactile Perception">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/shirticon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!--
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
-->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="http://nehasunil.com/" target="_blank">Neha Sunil</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://mhtippur.github.io/web/" target="_blank">Megha Tippur</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a> Arnau Portillo</a>,
                    <span class="author-block">
                    <a href="https://persci.mit.edu/people/adelson/" target="_blank"> Edward Adelson</a>,
                    <span class="author-block">
                    <a href="https://mcube.mit.edu/index.html" target="_blank"> Alberto Rodriguez</a>
                  </span>
          </div>

                <div class="is-size-5 publication-authors">
                  <img src="static/images/mit_logo_red.png" alt="MIT Logo" style="height: 2.5em; vertical-align: middle;"><br>
                  CoRL 2025</span>
                  <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="static/pdfs/CoRL2025_InAirReactiveManipulation.pdf" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Supplementary Link-->
              <span class="link-block">
                <a href="static/pdfs/CoRL2025_Supplemental_InAirReactiveManipulation.pdf" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://mhtippur.github.io/web/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. 
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. 
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. 
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser_video.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-left">
        <strong>Overview:</strong> We develop a visuotactile system capable of folding and hanging in-air using 
        dense visual representations and tactilely-supervised visual affordance networks.
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Manipulating clothing is challenging due to their complex, variable configurations and frequent self-occlusion. 
            While prior systems often rely on flattening garments, humans routinely identify keypoints in highly crumpled and suspended states. 
            We present a novel, task-agnostic, visuotactile framework that operates directly on crumpled clothingâ€”including in-air configurations that have not been addressed before. 
          </p>
          <p>
            Our approach combines global visual perception with local tactile feedback to enable robust, reactive manipulation. We train dense visual descriptors on a custom simulated dataset using a distributional loss that captures cloth symmetries and generates correspondence confidence estimates. 
            These estimates guide a reactive state machine that dynamically selects between folding strategies based on perceptual uncertainty. In parallel, we train a visuotactile grasp affordance network using high-resolution tactile feedback to supervise grasp success. 
            The same tactile classifier is used during execution for real-time grasp validation. 
            Together, these components enable a reactive, task-agnostic framework for in-air garment manipulation, including folding and hanging tasks. 
            Moreover, our dense descriptors serve as a versatile intermediate representation for other planning modalities, such as extracting grasp targets from human video demonstrations, paving the way for more generalizable and scalable garment manipulation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <div style="margin-top: 3rem;"></div>

    <!-- Simulation -->
     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Generation in Simulation</h2>
        <div class="content has-text-justified">
          <p>
            We use <strong>Blender</strong> to simulate a wide variety of shirt geometries and deformations, generating a large RGB-D dataset (1500 scenes) for training. 
            In addition to parameterizing the overall geometries, we incorporate <strong>hems, stitches, and sewing seams</strong> into our shirts to mimic realistic garments, enhancing visual realism 
            and providing key features helpful for correspondence. 
            Our method incorporates these finer details while <strong>preserving consistent vertex indexing across shirts</strong>, 
            enabling descriptors to align with a canonical template regardless of geometry, without relying on sparse skeleton keypoints.
          </p>
          
          <!-- Simulation Image -->
      <div class="simulation-image">
        <img src="static/images/blender_simulation_methodology.png" alt="Shirt simulation example"
            style="max-width:100%; height:auto; margin-top:1.5rem; border-radius:8px; margin-bottom: 1.5rem;">

          <p>
            Our animated simulation pipeline enables generation of a wide range of shirt types and configurations. Shown below are a few examples 
            different simulated shirts in both hanging in-air and on-table configurations. 
          </p>
          
          <div class="example-shirts-image">
            <img src="static/images/example_simulated_shirts.png" alt="Shirt simulation example"
                style="max-width:100%; height:auto; margin-top:1.5rem; border-radius:8px;">
        </div>
      </div>
    </div>
    <!--/ Simulation -->

    <div style="margin-top: 5rem;"></div>
    <!--Dense Correspondence with Distributive Loss -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Dense Correspondence with Distributional Loss</h2>
        <div class="content has-text-justified">

          <!-- Network Training Architecture -->
          <div class="training-image">
            <img src="static/images/training_new.png" alt="Shirt simulation example"
                style="max-width:100%; height:auto; margin-top:1.5rem; border-radius:8px;">
          </div>
          <div style="margin-top: 2rem;"></div>
          <p>
            To train the dense correspondence network, a pixel on the deformed shirt is queried. Because the vertex scheme across the different simulated shirts is consistent with 
            the canonical shirt mapping, the corresponding pixel match in simulation is found. The network outputs a dense descriptor for the shirt 
            where every pixel is mapped to an d-dimensional embedding, capturing the location of the pixel with respect to the canonical shirt in the descriptor space. 
          </p>
          <p>
            <strong>MHT MAYBE TAKE THIS PARAGRAPH OUT - TOO IN DEPTH FOR WEBSITE! </strong>Additionally, we train the network using a distributional loss. A multimodal isotropic Gaussian with modes at symmetric match points is used as 
            the target distribution. The probability estimator is found by taking the softmax over negative distances in the descriptor space. The model is 
            trained by minimizing the difference between the target distribution and the probability estimate, as measured by KL divergence. Training with 
            a distributional loss is advantageous because 
          </p>
          <p>
            Using a <strong>Distributional Loss </strong> for training our dense correspondence network provides several advantages, including allowing the network 
            to represent multiple valid matches for a pixel, <strong>capturing symmetries in the cloth</strong>, and by providing a <strong>built-in confidence metric</strong> needed to manipulate 
            garments in highly occluded states.  
          </p>
      </div>
    </div>
    <!--/ Dense Correspondence with Distributive Loss -->
  </div>

    <div style="margin-top: 5rem;"></div>
    <!--Visuotactile Grasp Affordance -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Visuotactile Grasp Affordance</h2>
        <div class="content has-text-justified">
          <p>
            Training in Simulation 
          </p>
          <div class="training-image">
            <img src="static/images/affordance_training_in_simulation.png" alt="Shirt simulation example"
                style="max-width:100%; height:auto; margin-top:1.5rem; border-radius:8px;">
          </div>
          <p>More Fun INformation </p>
            <video id="affordance_finetuning" autoplay muted loop playsinline height="100%"> 
              <source src="./static/videos/finetuning_grasp_affordance_1.mp4"
                type="video/mp4">
            </video>
      <h2 class="subtitle has-text-left">
      </div>
    </div>
    <!--/ Dense Correspondence with Distributive Loss -->

</section>





<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="static/pdfs/CoRL2025_InAirReactiveManipulation.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://mhtippur.github.io/inairclothmanip/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            This website template is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
